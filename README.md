
![img_sorriso.png](img%2Fimg_sorriso.png)


Manipulamos a soluçao [Face Mesh](https://google.github.io/mediapipe/solutions/face_mesh) no [MediaPipe](https://mediapipe.dev/index.html) para processar um vídeo ao vivo e gerar saídas úteis para o problema.


![img_1.png](img%2Fimg_1.png)

![img_6.png](img%2Fimg_6.png)

![img_7.png](img%2Fimg_7.png)

Utilizando a formula para obtenção do EAR:

![img_3.png](img%2Fimg_3.png)

Foi possível detectar a sonolência:

![img_4.png](img%2Fimg_4.png)

Você pode conferir outras soluções nesse [link](https://google.github.io/mediapipe/solutions/solutions.html).

Mais artigos:

[MediaPipe Holistic — Simultaneous Face, Hand and Pose Prediction, on Device](https://ai.googleblog.com/2020/12/mediapipe-holistic-simultaneous-face.html) que conta sobre a solução holistic e também traz exemplos de aplicações;
[On-Device, Real-Time Hand Tracking with MediaPipe](https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html) que apresenta a solução de detecção da mão Hand Tracking;
[Background Features in Google Meet, Powered by Web ML](https://ai.googleblog.com/2020/10/background-features-in-google-meet.html) que exibe a solução de segmentação de corpo; e
[Real-Time AR Self-Expression with Machine Learning](https://ai.googleblog.com/2019/03/real-time-ar-self-expression-with.html) que mostra uma aplicação da solução Face Mesh.
Testar alguns produtos criados e disponibilizados no [codepen](https://codepen.io/mediapipe); e
Manipular uma aplicação de um mouse e teclado com uma câmera virtual nesse [link](https://mediapipe.dev/demo/holistic_remote/).

Créditos: Alura e instrutora Mirla Costa

![img.png](img/img.png)